confusionMatrix(pred_y_dtree_pruned, test_y, positive = "2", mode = "prec_recall")
train_data <- fread("eeg_training.csv")
test_data <- fread("eeg_test.csv")
head(train_data)
head(test_data)
summary(train_data)
summary(test_data)
column_types <- sapply(train_data, class)
column_types
print(paste("number of observations in training data:",nrow(train_data)))
print(paste("number of NA's in train data:",sum(is.na(train_data))))
print(paste("number of observations in test data:",nrow(test_data)))
print(paste("number of NA's in test data:",sum(is.na(test_data))))
sum(is.na(train_data[,V14]))
train_data[, V14 := NULL]
print(paste("number of na's in training data after deleting V14 column:",sum(is.na(train_data))))
na.omit(train_data)
train_number_of_observations <- train_data[,.N]
test_number_of_observations <- test_data[,.N]
train_number_of_observations <- train_data[,.N]
test_number_of_observations <- test_data[,.N]
total_observations <- train_number_of_observations + test_number_of_observations
distribution_percentage_train <- train_number_of_observations / total_observations * 100
distribution_percentage_test <- test_number_of_observations / total_observations * 100
distribution_percentage_train
distribution_percentage_test
for (col in names(train_data[, !"V17"])) {
train_data <- train_data[!(get(col) > 50000)]
}
colnames(train_data)[16] <- "eyes_status"
colnames(test_data)[17] <- "eyes_status"
train_x <- train_data[,!"eyes_status"]
train_y <- train_data[,eyes_status]
test_x  <- test_data[,!"eyes_status"]
test_y  <- test_data[,eyes_status]
test_y <- factor(test_y, levels = c(1, 2), labels = c("1", "2"))
dtree_default <- rpart::rpart(eyes_status ~ ., method = "class", data = train_data)
printcp(dtree_default)
plotcp(dtree_default)
summary(dtree_default)
rpart.plot(dtree_default, type = 2, extra = 101, fallen.leaves = F, main = "Classification Tree for eye status", tweak=1.2)
dtree_full <- rpart::rpart(eyes_status ~ ., method = "class", data = train_data,
control = rpart.control(minsplit = 1, cp = 0))
printcp(dtree_full)
plotcp(dtree_full)
rpart.plot(dtree_full, type = 2, extra = 101, fallen.leaves = F, tweak = 1.2, main = "Entire Tree for eye status")
best_value <- which.min(dtree_full$cptable[, "xerror"])
best_cp_for_pruning <- dtree_full$cptable[best_value, "CP"]
dtree_pruned <- prune(dtree_full, cp = best_cp_for_pruning)
printcp(dtree_pruned)
rpart.plot(dtree_pruned, type = 2, extra = 101, fallen.leaves = F, tweak = 1.2, main = "Pruned Tree for eye status")
pred_y_dtree_default <- predict(dtree_default, newdata = test_x, type = "class")
pred_y_dtree_full <- predict(dtree_full, newdata = test_x, type = "class")
pred_y_dtree_pruned <- predict(dtree_pruned, newdata = test_x, type = "class")
confusionMatrix(pred_y_dtree_default, reference = test_y, positive = "2", mode = "prec_recall")
confusionMatrix(pred_y_dtree_full,test_y, positive = "2", mode = "prec_recall")
confusionMatrix(pred_y_dtree_pruned, test_y, positive = "2", mode = "prec_recall")
pred_y_dtree_default <- predict(dtree_default, newdata = test_x, type = "class")
pred_y_dtree_full <- predict(dtree_full, newdata = test_x, type = "class")
pred_y_dtree_pruned <- predict(dtree_pruned, newdata = test_x, type = "class")
confusionMatrix(pred_y_dtree_default, reference = test_y, positive = "2", mode = "prec_recall")
confusionMatrix(pred_y_dtree_full,test_y, positive = "2", mode = "prec_recall")
decision_tree_confusion_m <- confusionMatrix(pred_y_dtree_pruned, test_y, positive = "2", mode = "prec_recall")
decision_tree_confusion_m
# Set WD to the folder of the currently opened r file
if (rstudioapi::isAvailable()) {
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
}
# Load libraries ---------------------------------------------------------------
# Create our function "using()"
using <- \(pkg) {
# if a package is not installed, install it
if (!rlang::is_installed(pkg)) {
install.packages(pkg)
}
# load the package
library(pkg, character.only = TRUE)
}
using("data.table") # The data manipulation king
using("caret") # The ML swiss-knife - http://topepo.github.io/caret/available-models.html
using("plotly") # Beatiful interactive plots
using("ranger") # the fastest and better random forest implementation
using("adabag") # Adaboost
using("xgboost") # Extreme Gradient boosting
using("imbalance") # Oversampling
using("ROSE") # Synthetic generation of new data to rebalance
using("VIM") # imputation of missing values
data <- fread("./data/healthcare-dataset-stroke-data.csv")
# data[, gender := as.factor(gender)]
summary(data)
str(data)
#table(data$gender)
View(lapply(data, table))
data <- fread("./data/healthcare-dataset-stroke-data.csv",
colClasses = c("integer", "factor", "numeric",
rep("factor", 5),
rep("numeric", 2),
rep("factor", 2)),
na.strings = c("N/A","Unknown"))
data[, stroke := as.factor(ifelse(stroke == "1", "Yes", "No"))]
data[, ever_married := as.factor(ifelse(ever_married == "Yes", 1, 0))]
data
summary(data)
str(data)
# EDA --------------------------------------------------------------------------
my_numerical_columns <- colnames(data[, .SD, .SDcols = is.numeric])
my_categorical_columns <- colnames(data[, .SD, .SDcols = is.factor])
scatterplots <- lapply(my_numerical_columns,
function(col) {
plot_ly(data   = data,
x      = ~1:nrow(data),
y      = ~get(col),
color  = ~stroke,
colors = c("Green","Blue"),
type   = "scattergl",
mode   = "markers",
showlegend = FALSE,
marker = list(size = 3)) |>
layout(yaxis = list(title = col))
})
subplot(scatterplots, titleY = T, nrows = 2)
boxplots <- lapply(my_numerical_columns,
function(col) {
plot_ly(data   = data,
x      = ~stroke,
y      = ~get(col),
color  = ~stroke,
colors = c("Green","Blue"),
type   = "box",
showlegend = FALSE) |>
layout(yaxis = list(title = col))
})
subplot(boxplots, titleY = T, nrows = 2)
densityplots <- lapply(my_numerical_columns,
function(col) {
show_legend <- ifelse(col == "id", TRUE, FALSE)
kdensity_yes <- density(data[stroke=="Yes",get(col)], na.rm = T)
kdensity_no <- density(data[stroke=="No",get(col)], na.rm = T)
plot_ly(type = "scatter", mode = "lines", fill = "tozeroy", showlegend = show_legend) |>
add_trace(x=kdensity_yes$x, y=kdensity_yes$y, name = "Stroke", color = I("orange")) |>
add_trace(x=kdensity_no$x, y=kdensity_no$y, name = "No Stroke", color = I("darkgreen")) |>
layout(yaxis = list(title = col))
})
subplot(densityplots, titleY = T, nrows = 2)
# We should look also at the categorical variables
barplots <- lapply(my_categorical_columns[my_categorical_columns!="stroke"],
function(col) {
show_legend <- ifelse(col == "gender", TRUE, FALSE)
counters <- data[, .(stroke = nrow(.SD[stroke == "Yes"]) / .N,
no_stroke = nrow(.SD[stroke == "No"]) / .N),
col]
plot_ly(data   = counters, type   = "bar", showlegend = show_legend) |>
add_trace(x = ~get(col), y = ~no_stroke, name = "No Stroke", color = I("orange")) |>
add_trace(x = ~get(col), y = ~stroke, name = "Stroke", color = I("darkgreen")) |>
layout(yaxis = list(title = col), barmode = "stack")
})
subplot(barplots, titleY = T, nrows = 2, margin = 0.05)
# Preprocessing ----------------------------------------------------------------
# It's ordered. Let's shuffle it just in case
set.seed(123)
data<-data[sample(1:nrow(data))]
## Dealing with NAs ----
sum(is.na(data))
colSums(is.na(data))
### Option 1: Omit ----
# Can observations (rows) with NAs be dropped? No, losing so much data is a pity.
nrow(na.omit(data))/nrow(data)
### Option 1: Omit ----
# Can observations (rows) with NAs be dropped? No, losing so much data is a pity.
nrow(na.omit(data))/nrow(data)
# Can features (columns) with NAs be dropped?
# I would not do it because smoking could be quite a predictor for stroke.
plot_ly(data, y = ~bmi, color = ~stroke, type = "box")
data[,.(perc_stroke=sum(stroke=="Yes")/.N*100),smoking_status]
### Option 2: Manual imputation ----
# For example
# A. Substitute with the median (Easiest, suggested only if the NAs are random):
#setnafill(data, type = "const", fill = median(data[,bmi], na.rm = T), cols = "bmi")
data[is.na(bmi), bmi := median(data[,bmi], na.rm = T)]
# B. Substitute with the median considering some grouping
data[, median_bmi := median(bmi, na.rm = T), .(hypertension, ever_married)]
data[is.na(bmi), bmi := median_bmi]
data[,median_bmi:=NULL]
### Option 3. Model-based imputation ----
# For example, kNN with VIM
data.imputed<-VIM::kNN(data, variable = c("bmi", "smoking_status"), imp_var = F)
VIM::aggr(data)
?aggr
VIM::matrixplot(data)
?matrixplot
# Train/Test -------------------------------------------------------------------
data[,id:=NULL]
set.seed(123)
idx <- createDataPartition(data[, stroke], p = .8, list = F, times = 1)
training <- data[idx]
test <- data[!idx]
training<-VIM::kNN(training, variable = c("bmi", "smoking_status"), imp_var = F)
test <- na.omit(test)
training_x <- training[,!"stroke"]
training_y <- training[,stroke]
test_x <- test[,!"stroke"]
test_y <- test[,stroke]
training[,.N,stroke]
test[,.N,stroke]
training[,.N/nrow(training),stroke]
test[,.N/nrow(test),stroke]
# Ranger -----------------------------------------------------------------------
## Raw data ----
# we can try without oversampling
# fit.ranger <- ranger(stroke ~ ., data = training) # default parameters
rf.orig <- ranger(x = training_x, y = training_y) # default parameters
# Results on training set
confusionMatrix(data = rf.orig$predictions, reference = training_y,
positive = "Yes", mode = "prec_recall")
# results on test set
my_pred <- predict(object = rf.orig, data = test_x)
confusionMatrix(data = my_pred$predictions, reference = test_y, positive = "Yes", mode = "prec_recall")
## Rebalancing ----------------------------------------------------------------
# Oversampling or undersampling
#training.rose <- ovun.sample(stroke ~ ., data = training,
#                              method = "over", seed = 123, p = 0.4)$data
# Synthetic generation
training.rose <- ROSE(stroke ~ ., data = training,
seed = 123, p = 0.5)$data
setDT(training.rose)
training[,.N,stroke]
training.rose[,.N,stroke]
training.rose_x <- training.rose[,!"stroke"]
training.rose_y <- training.rose[,stroke]
# Training
rf.rebalanced <- ranger(x = training.rose_x, y= training.rose_y) # default parameters
# results on training data
confusionMatrix(data = rf.rebalanced$predictions, reference = training.rose_y,
positive = "Yes", mode = "prec_recall")
# results on test data
my_pred_reb <- predict(rf.rebalanced, data = test_x)
confusionMatrix(data = my_pred_reb$predictions, reference = test_y,
positive = "Yes", mode = "prec_recall")
## Feature Importance ----
# Let's create a random feature
# We expect that other features are much more important than the random one
training.rose[,random:=runif(nrow(training.rose), 1, 100)]
fit.ranger <- ranger(stroke ~ ., data = training.rose, importance = "permutation")
View(fit.ranger)
colSums(is.na(data))
### Option 3. Model-based imputation ----
# For example, kNN with VIM
data.imputed<-VIM::kNN(data, variable = c("bmi", "smoking_status"), imp_var = F)
library(e1071)
svm_model<- svm(y ~ .,
data = train_data,
type = "C-classification",
kernel = "linear",
scale = FALSE)
svm_model<- svm(eyes_status ~ .,
data = train_data,
type = "C-classification",
kernel = "linear",
scale = FALSE)
svm_model
svm_model<- svm(eyes_status ~ .,
data = train_data,
type = "C-classification",
kernel = "linear",
scale = FALSE)
svm_model
svm_model$index
svm_model$SV
svm_model$rho
svm_model$coefs
pred_train <- predict(svm_model, train_data)
mean(pred_train == train_data$eyes_status)
pred_train <- predict(svm_model, train_data)
mean(pred_train == train_data$eyes_status)
pred_test <- predict(svm_model, test_data)
mean(pred_test == train_data$eyes_status)
pred_train <- predict(svm_model, train_data)
mean(pred_train == train_data$eyes_status)
pred_test <- predict(svm_model, test_data)
mean(pred_test == test_data$eyes_status)
svm_model<- svm(eyes_status ~ .,
data = train_data,
type = "C-classification",
kernel = "linear",
scale = FALSE)
svm_model
svm_model$index
svm_model$SV
svm_model$rho
svm_model<- svm(eyes_status ~ .,
data = train_data,
type = "C-classification",
kernel = "linear",
scale = FALSE)
svm_model
svm_model$index
svm_model$SV
svm_model$rho
pred_train <- predict(svm_model, train_data)
mean(pred_train == train_data$eyes_status)
pred_test <- predict(svm_model, test_data)
mean(pred_test == test_data$eyes_status)
plot(x=svm_model, data = train_data)
plot(x=svm_model, data = train_data)
plot(x=svm_model, data = train_data)
plot(x=svm_model, data = train_data, V1~V2)
plot(x=svm_model, data = train_data, V1~V5)
plot(x=svm_model, data = train_data, V1~V8)
plot(x=svm_model, data = train_data, V2~V8)
plot(x=svm_model, data = train_data, V5~V8)
knitr::opts_chunk$set(echo = TRUE)
svm_model<- svm(eyes_status ~ .,
data = train_data,
type = "C-classification",
kernel = "radial",
cost = 1,
degree = 2,
scale = FALSE)
knitr::opts_chunk$set(echo = TRUE)
library(data.table)
library(plotly)
library(caret)
library(rpart)
library(rpart.plot)
library(mlr3)
library(gridExtra)
library(e1071)
train_data <- fread("eeg_training.csv")
test_data <- fread("eeg_test.csv")
head(train_data)
head(test_data)
summary(train_data)
summary(test_data)
column_types <- sapply(train_data, class)
column_types
plots1 <- list()
for (i in colnames(train_data[, .(V1,V2,V3,V4,V5,V6)])) {
plots1[[i]] <- plot_ly(data = train_data, x = 1:nrow(train_data), y = train_data[,get(i)], color =train_data[,V17],
type = "scatter", mode = "markers")
}
plots2 <- list()
for (i in colnames(train_data[, .(V7,V8,V9,V10,V11,V12)])) {
plots2[[i]] <- plot_ly(data = train_data, x = 1:nrow(train_data), y = train_data[,get(i)], color =train_data[,V17],
type = "scatter", mode = "markers")
}
plots3 <- list()
for (i in colnames(train_data[, .(V13,V14,V15,V16)])) {
plots3[[i]] <- plot_ly(data = train_data, x = 1:nrow(train_data), y = train_data[,get(i)], color =train_data[,V17],
type = "scatter", mode = "markers")
}
subplot(plots1, nrows =3 , titleY = T, margin = 0.05)
subplot(plots2, nrows =3 , titleY = T, margin = 0.05)
subplot(plots3, nrows =2 , titleY = T, margin = 0.05)
print(paste("number of observations in training data:",nrow(train_data)))
print(paste("number of NA's in train data:",sum(is.na(train_data))))
print(paste("number of observations in test data:",nrow(test_data)))
print(paste("number of NA's in test data:",sum(is.na(test_data))))
sum(is.na(train_data[,V14]))
train_data[, V14 := NULL]
print(paste("number of na's in training data after deleting V14 column:",sum(is.na(train_data))))
na.omit(train_data)
train_number_of_observations <- train_data[,.N]
test_number_of_observations <- test_data[,.N]
train_number_of_observations <- train_data[,.N]
test_number_of_observations <- test_data[,.N]
total_observations <- train_number_of_observations + test_number_of_observations
distribution_percentage_train <- train_number_of_observations / total_observations * 100
distribution_percentage_test <- test_number_of_observations / total_observations * 100
distribution_percentage_train
distribution_percentage_test
for (col in names(train_data[, !"V17"])) {
train_data <- train_data[!(get(col) > 50000)]
}
colnames(train_data)[16] <- "eyes_status"
colnames(test_data)[17] <- "eyes_status"
train_x <- train_data[,!"eyes_status"]
train_y <- train_data[,eyes_status]
test_x  <- test_data[,!"eyes_status"]
test_y  <- test_data[,eyes_status]
test_y <- factor(test_y, levels = c(1, 2), labels = c("1", "2"))
dtree_default <- rpart::rpart(eyes_status ~ ., method = "class", data = train_data)
printcp(dtree_default)
plotcp(dtree_default)
summary(dtree_default)
rpart.plot(dtree_default, type = 2, extra = 101, fallen.leaves = F, main = "Classification Tree for eye status", tweak=1.2)
dtree_full <- rpart::rpart(eyes_status ~ ., method = "class", data = train_data,
control = rpart.control(minsplit = 1, cp = 0))
printcp(dtree_full)
plotcp(dtree_full)
rpart.plot(dtree_full, type = 2, extra = 101, fallen.leaves = F, tweak = 1.2, main = "Entire Tree for eye status")
best_value <- which.min(dtree_full$cptable[, "xerror"])
best_cp_for_pruning <- dtree_full$cptable[best_value, "CP"]
dtree_pruned <- prune(dtree_full, cp = best_cp_for_pruning)
printcp(dtree_pruned)
rpart.plot(dtree_pruned, type = 2, extra = 101, fallen.leaves = F, tweak = 1.2, main = "Pruned Tree for eye status")
pred_y_dtree_default <- predict(dtree_default, newdata = test_x, type = "class")
pred_y_dtree_full <- predict(dtree_full, newdata = test_x, type = "class")
pred_y_dtree_pruned <- predict(dtree_pruned, newdata = test_x, type = "class")
confusionMatrix(pred_y_dtree_default, reference = test_y, positive = "2", mode = "prec_recall")
confusionMatrix(pred_y_dtree_full,test_y, positive = "2", mode = "prec_recall")
decision_tree_confusion_m <- confusionMatrix(pred_y_dtree_pruned, test_y, positive = "2", mode = "prec_recall")
decision_tree_confusion_m
svm_model<- svm(eyes_status ~ .,
data = train_data,
type = "C-classification",
kernel = "linear",
cost = 1,
scale = FALSE)
svm_model
svm_model$index
svm_model$SV
svm_model$rho
pred_train <- predict(svm_model, train_data)
mean(pred_train == train_data$eyes_status)
pred_test <- predict(svm_model, test_data)
mean(pred_test == test_data$eyes_status)
svm_model<- svm(eyes_status ~ .,
data = train_data,
type = "C-classification",
kernel = "polynomial",
cost = 1,
degree = 2,
scale = FALSE)
svm_model
pred_train <- predict(svm_model, train_data)
mean(pred_train == train_data$eyes_status)
pred_test <- predict(svm_model, test_data)
mean(pred_test == test_data$eyes_status)
svm_model<- svm(eyes_status ~ .,
data = train_data,
type = "C-classification",
kernel = "radial",
cost = 1,
degree = 2,
scale = FALSE)
svm_model
pred_train <- predict(svm_model, train_data)
mean(pred_train == train_data$eyes_status)
pred_test <- predict(svm_model, test_data)
mean(pred_test == test_data$eyes_status)
colSums(is.na(data))
### Option 3. Model-based imputation ----
# For example, kNN with VIM
data.imputed<-VIM::kNN(data, variable = c("bmi", "smoking_status"), imp_var = F)
VIM::aggr(data)
VIM::matrixplot(data)
rf.orig <- ranger(x = train_x, y = train_y)
library(data.table)
library(plotly)
library(caret)
library(rpart)
library(rpart.plot)
library(mlr3)
library(gridExtra)
library(e1071)
library(ranger)
rf.orig <- ranger(x = train_x, y = train_y)
confusionMatrix(data = rf.orig$predictions, reference = training_y,
positive = "2", mode = "prec_recall")
rf.orig <- ranger(x = train_x, y = train_y)
confusionMatrix(data = rf.orig$predictions, reference = train_y,
positive = "2", mode = "prec_recall")
train_y
rf.orig <- ranger(x = train_x, y = train_y)
confusionMatrix(data = rf.orig$predictions, reference = train_y,
positive = "2", mode = "prec_recall")
train_y <- as.factor(train_y)
rf.orig <- ranger(x = train_x, y = train_y)
confusionMatrix(data = rf.orig$predictions, reference = train_y,
positive = "2", mode = "prec_recall")
my_pred <- predict(object = rf.orig, data = test_x)
confusionMatrix(data = my_pred$predictions, reference = test_y, positive = "2", mode = "prec_recall")
# Ranger -----------------------------------------------------------------------
## Raw data ----
# we can try without oversampling
# fit.ranger <- ranger(stroke ~ ., data = training) # default parameters
rf.orig <- ranger(x = training_x, y = training_y) # default parameters
# Results on training set
confusionMatrix(data = rf.orig$predictions, reference = training_y,
positive = "Yes", mode = "prec_recall")
# results on test set
my_pred <- predict(object = rf.orig, data = test_x)
confusionMatrix(data = my_pred$predictions, reference = test_y, positive = "Yes", mode = "prec_recall")
## Rebalancing ----------------------------------------------------------------
# Oversampling or undersampling
#training.rose <- ovun.sample(stroke ~ ., data = training,
#                              method = "over", seed = 123, p = 0.4)$data
# Synthetic generation
training.rose <- ROSE(stroke ~ ., data = training,
seed = 123, p = 0.5)$data
setDT(training.rose)
training[,.N,stroke]
training.rose[,.N,stroke]
training.rose_x <- training.rose[,!"stroke"]
training.rose_y <- training.rose[,stroke]
# Training
rf.rebalanced <- ranger(x = training.rose_x, y= training.rose_y) # default parameters
# results on training data
confusionMatrix(data = rf.rebalanced$predictions, reference = training.rose_y,
positive = "Yes", mode = "prec_recall")
# results on test data
my_pred_reb <- predict(rf.rebalanced, data = test_x)
confusionMatrix(data = my_pred_reb$predictions, reference = test_y,
positive = "Yes", mode = "prec_recall")
ada <- adabag::boosting(eyes_statys ~ ., data = train_data, mfinal = 200)
ada <- adabag::boosting(eyes_statys ~ ., data = train_data, mfinal = 200)
ada <- adabag::boosting(eyes_status ~ ., data = train_data, mfinal = 200)
ada <- adabag::boosting(eyes_status ~ ., data = train_data, mfinal = 200)
ada <- adabag::boosting(eyes_status~ ., data = train_data, mfinal = 200)
# adaboost ---------------------------------------------------------------------
ada <- adabag::boosting(stroke ~ ., data = training.rose, mfinal = 200)
my_pred_adaboost <- predict(ada, newdata = test_x)
